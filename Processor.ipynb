{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: MatplotlibDeprecationWarning: \n",
      "The mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "from particle import Particle\n",
    "from mpl_toolkits.axes_grid.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_pars(df):\n",
    "    '''From a given DataFrame return the largest number of particles from one event'''\n",
    "    \n",
    "    arr = df['pdgf'].to_numpy()\n",
    "    arr = ak.Array(arr)\n",
    "    counts = ak.num(arr)\n",
    "    \n",
    "    return np.max(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_value(arr, num, val):\n",
    "    '''Take in a given 2D awkward array and pad it with a value to a specified number'''\n",
    "    \n",
    "    awk = ak.Array(arr)\n",
    "    padded = ak.pad_none(awk, num, axis = 1)\n",
    "    arr = ak.fill_none(padded, val)\n",
    "    arr = ak.to_numpy(arr)\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_energy_df(df, pars, is_all, is_leading, is_sum, is_cal_eng, num = 52, fill = 0):\n",
    "    \n",
    "    # Pad each array\n",
    "    pdgf = pad_value(df['pdgf'].to_numpy(), num, 0)\n",
    "    ef = pad_value(df['Ef'].to_numpy(), num, 0)\n",
    "    \n",
    "    pxf = pad_value(df['pxf'].to_numpy(), num, 0)\n",
    "    pyf = pad_value(df['pyf'].to_numpy(), num, 0)\n",
    "    pzf = pad_value(df['pzf'].to_numpy(), num, 0)\n",
    "    \n",
    "    df_new = pd.DataFrame()\n",
    "    df_new['event'] = df.index\n",
    "    \n",
    "    # Go through each particle #\n",
    "    for par in pars:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # make arrays of mom, energy where that particle is for each event\n",
    "        ef_par = np.where(pdgf == par, ef, fill)\n",
    "        pxf_par = np.where(pdgf == par, pxf, fill)\n",
    "        pyf_par = np.where(pdgf == par, pyf, fill)\n",
    "        pzf_par = np.where(pdgf == par, pzf, fill)\n",
    "        \n",
    "        ### SORT BASED ON EF ##\n",
    "        # Index to sort by \n",
    "        index = np.argsort(-ef_par)\n",
    "\n",
    "        # Sort ef, px, py, pz\n",
    "        ef_par = np.take_along_axis(ef_par, index, axis=1)\n",
    "        pxf_par = np.take_along_axis(pxf_par, index, axis=1)\n",
    "        pyf_par = np.take_along_axis(pyf_par, index, axis=1)\n",
    "        pzf_par = np.take_along_axis(pzf_par, index, axis=1)\n",
    "        \n",
    "        ## Remove zero momentum particles ##\n",
    "        # get rid of zeros in ef (already zero in pxf, pyf, pzf)\n",
    "        if(fill == 0):\n",
    "            ef_par = np.where(pxf_par == 0, 0, ef_par)\n",
    "        else:\n",
    "            # Remove from all arrays\n",
    "            ef_par = np.where(pxf_par == 0, fill, ef_par)\n",
    "            pxf_par = np.where(pxf_par == 0, fill, pxf_par)\n",
    "            pyf_par = np.where(pxf_par == 0, fill, pyf_par)\n",
    "            pzf_par = np.where(pxf_par == 0, fill, pzf_par)\n",
    "            \n",
    "        ef_par = ak.to_awkward0(ef_par)\n",
    "        pxf_par = ak.to_awkward0(pxf_par)\n",
    "        pyf_par = ak.to_awkward0(pyf_par)\n",
    "        pzf_par = ak.to_awkward0(pzf_par)\n",
    "    \n",
    "        if is_all:\n",
    "            \n",
    "            ## Remove extra fill values ##\n",
    "            ef_pars =  ef_par[~(ef_par == fill)]\n",
    "            pxf_pars = pxf_par[~(pxf_par == fill)]\n",
    "            pyf_pars = pyf_par[~(pyf_par == fill)]\n",
    "            pzf_pars = pzf_par[~(pzf_par == fill)]\n",
    "        \n",
    "            ## Add arrays to the new dataframe ##\n",
    "            df_new['Ef ' + str(par)] = ak.to_numpy(ef_pars)\n",
    "            df_new['pxf ' + str(par)] = ak.to_numpy(pxf_pars)\n",
    "            df_new['pyf ' + str(par)] = ak.to_numpy(pyf_pars)\n",
    "            df_new['pzf ' + str(par)] = ak.to_numpy(pzf_pars)\n",
    "       \n",
    "        if is_leading:\n",
    "            ## Add arrays to the new dataframe ##\n",
    "            df_new['Ef ' + str(par) + ' l'] = ef_par[::, 0]\n",
    "            df_new['pxf ' + str(par) + ' l'] = pxf_par[::, 0]\n",
    "            df_new['pyf ' + str(par) + ' l'] = pyf_par[::, 0]\n",
    "            df_new['pzf ' + str(par) + ' l'] = pzf_par[::, 0] \n",
    "        \n",
    "        if is_sum:\n",
    "            ## Add arrays to the new dataframe ##\n",
    "            df_new['Ef ' + str(par) + ' sum'] = np.sum(ak.Array(ef_par), axis = 1)\n",
    "            df_new['pxf ' + str(par) + ' sum'] = np.sum(ak.Array(pxf_par), axis = 1)\n",
    "            df_new['pyf ' + str(par) + ' sum'] = np.sum(ak.Array(pyf_par), axis = 1)\n",
    "            df_new['pzf ' + str(par) + ' sum'] = np.sum(ak.Array(pzf_par), axis = 1) \n",
    "        \n",
    "        if is_cal_eng:\n",
    "            ## Add arrays to the new dataframe ##\n",
    "            p = Particle.from_pdgid(par)\n",
    "            ef_par = ef_par.astype('float')\n",
    "            ef_par[ef_par == 0] = np.nan\n",
    "            \n",
    "            if (par == 2112 or par == 2212 or par == 3112 or par == 3122 or par == 3212 or par == 3222):\n",
    "                mass = p.mass/1000\n",
    "            else:\n",
    "                mass = 0\n",
    "            df_new['cal ' + str(par)] = np.sum(np.nan_to_num(ak.Array(ef_par) - mass), axis = 1) \n",
    "        \n",
    "        print('Done with: ', str(par), 'time took: ', time.time() - start_time, ' still working ...')\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/laurazichi/Desktop/base_generation_with_weights_9Jun_FSIFix.hdf'\n",
    "gst_df = pd.read_hdf(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lep_df = gst_df[np.sqrt((gst_df['pxl']**2 + gst_df['pyl']**2)) > 0.4]\n",
    "lep_cut = np.array(lep_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lep_df = pd.read_hdf(\"lep_cut_df.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with:  -321 time took:  5.224646329879761  still working ...\n",
      "Done with:  -311 time took:  5.190582990646362  still working ...\n",
      "Done with:  -211 time took:  5.10597825050354  still working ...\n",
      "Done with:  -13 time took:  5.259606122970581  still working ...\n",
      "Done with:  -11 time took:  5.105317115783691  still working ...\n",
      "Done with:  11 time took:  5.273281812667847  still working ...\n",
      "Done with:  13 time took:  5.178674936294556  still working ...\n",
      "Done with:  22 time took:  5.239135026931763  still working ...\n",
      "Done with:  111 time took:  5.169209718704224  still working ...\n",
      "Done with:  211 time took:  5.170384168624878  still working ...\n",
      "Done with:  311 time took:  5.100643157958984  still working ...\n",
      "Done with:  321 time took:  5.357055902481079  still working ...\n",
      "Done with:  2112 time took:  5.567325115203857  still working ...\n",
      "Done with:  2212 time took:  5.589590072631836  still working ...\n",
      "Done with:  3112 time took:  5.378298044204712  still working ...\n",
      "Done with:  3122 time took:  5.3158299922943115  still working ...\n",
      "Done with:  3212 time took:  5.295845031738281  still working ...\n",
      "Done with:  3222 time took:  5.300241947174072  still working ...\n"
     ]
    }
   ],
   "source": [
    "pars_all = np.array([-321, -311, -211,  -13,  -11,   11,   13,   22,  111,  211,  311,  321, 2112, 2212,\n",
    " 3112, 3122, 3212,3222])\n",
    "df_new = make_energy_df(lep_df, pars_all, False, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_hdf('fast_sorted.hdf', 'lep_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
